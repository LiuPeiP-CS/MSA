#1 the datasets are from the paper: [Learning Modality-Specific Representations with Self-Supervised Multi-Task for Multimodal Sentiment Analysis (AAA2021)]

### usage

# we have the aligned and unaligned features from self-MM [Learning Modality-Specific Representations with Self-Supervised Multi-Task for Multimodal Sentiment Analysis (AAA2021)]
# we have the aligned features from MAG [Integrating Multimodal Information in Large Pretrained Transformers]
# we can get the aligned features from MISA but need to install the SDK [CMU Multimodal SDK]